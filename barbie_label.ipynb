{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Please run this notebook in Google Colaboratory.\n",
        "\n",
        "Please upload your unlabelled csv to this folder:\n",
        "\n",
        "https://drive.google.com/drive/folders/1LISkmkab8S7DBECTFb65DqD3a3_GSeI8?usp=sharing\n",
        "\n",
        "Please note that the table should contain a `cleaned_text` column.\n",
        "\n",
        "|...|cleaned_text|...|\n",
        "|:---:|:---:|:---:|\n",
        "|$\\vdots$|review 1|$\\vdots$|\n",
        "|$\\vdots$|$\\vdots$|$\\vdots$|\n",
        "\n",
        "This script will save a labelled csv named labaled.csv"
      ],
      "metadata": {
        "id": "lJCpewZkzTr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preamble"
      ],
      "metadata": {
        "id": "GAP3UpH-xAvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX3ovoe5w66V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This folder cointains our model and tokenizer\n",
        "'''\n",
        "model_folder_id = '1mfbSHZ8pVC4WOvWPCDma-8n4A25dtty2'\n",
        "gdown.download_folder(id=model_folder_id,output=\"model\",quiet=False,use_cookies=False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "kybrf5iTxpRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This folder should contain your a csv of all the reviews you want to label\n",
        "'''\n",
        "test_folder_id = '1LISkmkab8S7DBECTFb65DqD3a3_GSeI8'\n",
        "gdown.download_folder(id=test_folder_id,output=\"test\",quiet=False,use_cookies=False)"
      ],
      "metadata": {
        "id": "f7Gpka7Hy7Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_folder = \"test\"\n",
        "\n",
        "csv_files = glob.glob(os.path.join(downloaded_folder, \"*.csv\"))\n",
        "\n",
        "if len(csv_files) != 1:\n",
        "    raise ValueError(f\"Expected 1 CSV in '{downloaded_folder}', found {len(csv_files)}\")\n",
        "\n",
        "csv_file_path = csv_files[0]\n",
        "new_name = os.path.join(downloaded_folder, \"reviews.csv\")\n",
        "os.rename(csv_file_path, new_name)\n",
        "\n",
        "print(f\"CSV downloaded and renamed to: {new_name}\")"
      ],
      "metadata": {
        "id": "eAR0KXkaZv_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5755643"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHwXueVTJLxg"
      },
      "source": [
        "df_test = pd.read_csv('/content/test/reviews.csv')\n",
        "display(df_test.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "167c4a28"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('/content/model/')\n",
        "\n",
        "tokenized_inputs = tokenizer(\n",
        "    df_test['cleaned_text'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=128,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "test_dataset = TensorDataset(tokenized_inputs['input_ids'], tokenized_inputs['attention_mask'])\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "print(\"Tokenizer loaded successfully.\")\n",
        "print(\"Text data tokenized and DataLoader created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7a3b44c"
      },
      "source": [
        "# Load model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73b6332b"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('/content/model/')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully and moved to device.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b5a44a"
      },
      "source": [
        "# Perform inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "185acf71"
      },
      "source": [
        "import torch\n",
        "\n",
        "all_logits = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    input_ids, attention_mask = batch\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        all_logits.append(logits)\n",
        "\n",
        "all_logits = torch.cat(all_logits, dim=0)\n",
        "print(\"Inference completed and logits collected.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56a25442"
      },
      "source": [
        "# Process predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8924b8c1"
      },
      "source": [
        "probabilities = torch.softmax(all_logits, dim=1)\n",
        "predicted_labels = torch.argmax(probabilities, dim=1)\n",
        "predicted_labels_np = predicted_labels.cpu().numpy()\n",
        "\n",
        "print(\"Softmax applied, predicted labels determined, and converted to NumPy array.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "514b2f5d"
      },
      "source": [
        "# Save results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0d75237"
      },
      "source": [
        "df_test['predicted_label'] = predicted_labels_np\n",
        "df_test.to_csv('labeled.csv', index=False)\n",
        "\n",
        "print(\"Predicted labels added to DataFrame and saved to 'test_labeled.csv'.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}