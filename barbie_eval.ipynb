{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Please run this notebook in Google Colaboratory.\n",
        "\n",
        "Please upload your labelled testing csv to this folder:\n",
        "\n",
        "https://drive.google.com/drive/folders/1LISkmkab8S7DBECTFb65DqD3a3_GSeI8?usp=sharing\n",
        "\n",
        "Please note that the table should contain a `cleaned_text` and a `classification` column.\n",
        "\n",
        "|...|cleaned_text|classification|...|\n",
        "|:---:|:---:|:---:|:---:|\n",
        "|$\\vdots$|review 1|label 1|$\\vdots$|\n",
        "|$\\vdots$|$\\vdots$|$\\vdots$|$\\vdots$|\n"
      ],
      "metadata": {
        "id": "lJCpewZkzTr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preamble"
      ],
      "metadata": {
        "id": "GAP3UpH-xAvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OX3ovoe5w66V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, classification_report, confusion_matrix\n",
        ")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This folder cointains our model and tokenizer\n",
        "'''\n",
        "model_folder_id = '1mfbSHZ8pVC4WOvWPCDma-8n4A25dtty2'\n",
        "gdown.download_folder(id=model_folder_id,output=\"model\",quiet=False,use_cookies=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kybrf5iTxpRU",
        "outputId": "98fff8b4-cca6-4a9c-f137-1a11d55ce7b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1qnxS0IVsmQOGnHt1byAmXZi1Oge0LbZc config.json\n",
            "Processing file 1vFieRhcj7WnU7oOCZQJlEl2sn1OFzBzV model.safetensors\n",
            "Processing file 1JR3-HU2Fb9sYeO1IZEejuxtnJyEpLRSs special_tokens_map.json\n",
            "Processing file 1hKhI8w1CWhcFeyH2qazL6okzf9OQZarM tokenizer_config.json\n",
            "Processing file 1YtB2-pNBmJHgG-Z3RrodO0rr_uZ1yC5t vocab.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1qnxS0IVsmQOGnHt1byAmXZi1Oge0LbZc\n",
            "To: /content/model/config.json\n",
            "100%|██████████| 707/707 [00:00<00:00, 1.89MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1vFieRhcj7WnU7oOCZQJlEl2sn1OFzBzV\n",
            "From (redirected): https://drive.google.com/uc?id=1vFieRhcj7WnU7oOCZQJlEl2sn1OFzBzV&confirm=t&uuid=de0987c3-251f-4cdf-8fdd-a79fa3c0b1ec\n",
            "To: /content/model/model.safetensors\n",
            "100%|██████████| 438M/438M [00:02<00:00, 203MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JR3-HU2Fb9sYeO1IZEejuxtnJyEpLRSs\n",
            "To: /content/model/special_tokens_map.json\n",
            "100%|██████████| 132/132 [00:00<00:00, 412kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hKhI8w1CWhcFeyH2qazL6okzf9OQZarM\n",
            "To: /content/model/tokenizer_config.json\n",
            "100%|██████████| 1.33k/1.33k [00:00<00:00, 3.91MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YtB2-pNBmJHgG-Z3RrodO0rr_uZ1yC5t\n",
            "To: /content/model/vocab.txt\n",
            "100%|██████████| 262k/262k [00:00<00:00, 86.0MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model/config.json',\n",
              " 'model/model.safetensors',\n",
              " 'model/special_tokens_map.json',\n",
              " 'model/tokenizer_config.json',\n",
              " 'model/vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This folder should contain your testing files\n",
        "'''\n",
        "test_folder_id = '1LISkmkab8S7DBECTFb65DqD3a3_GSeI8'\n",
        "gdown.download_folder(id=test_folder_id,output=\"test\",quiet=False,use_cookies=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f7Gpka7Hy7Kp",
        "outputId": "89f963c0-2d16-4444-a009-004e81c77f8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1xM7Tg7pnLGbcw3mcYQj3xgyAJICvmaPO test_final.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xM7Tg7pnLGbcw3mcYQj3xgyAJICvmaPO\n",
            "To: /content/test/test_final.csv\n",
            "100%|██████████| 44.1k/44.1k [00:00<00:00, 55.5MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test/test_final.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "downloaded_folder = \"test\"\n",
        "\n",
        "csv_files = glob.glob(os.path.join(downloaded_folder, \"*.csv\"))\n",
        "\n",
        "if len(csv_files) != 1:\n",
        "    raise ValueError(f\"Expected 1 CSV in '{downloaded_folder}', found {len(csv_files)}\")\n",
        "\n",
        "csv_file_path = csv_files[0]\n",
        "new_name = os.path.join(downloaded_folder, \"reviews.csv\")\n",
        "os.rename(csv_file_path, new_name)\n",
        "\n",
        "print(f\"CSV downloaded and renamed to: {new_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvNLoggHdr0W",
        "outputId": "5dc65f73-e733-4d48-b2f0-a194c73ba52f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV downloaded and renamed to: test/reviews.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "l94f_9kD7CBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "df = pd.read_csv('/content/test/reviews.csv')\n",
        "\n",
        "# Extract text and labels\n",
        "texts = df['cleaned_text'].tolist()\n",
        "labels = df['classification'].tolist()  # assuming 0/1 integers\n",
        "\n",
        "# Load tokenizer\n",
        "save_directory = '/content/model'\n",
        "tokenizer = BertTokenizer.from_pretrained(save_directory)\n",
        "\n",
        "# Tokenize the dataset\n",
        "encoded_dict = tokenizer.batch_encode_plus(\n",
        "    texts,\n",
        "    add_special_tokens=True,      # Add '[CLS]' and '[SEP]'\n",
        "    max_length=128,        # Pad and truncate all reviews\n",
        "    padding='max_length',         # Pad to the max_length\n",
        "    truncation=True,              # Truncate sequences to max_length\n",
        "    return_attention_mask=True,   # Return attention mask\n",
        "    return_tensors='pt',          # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "# Convert labels to tensor\n",
        "labels_tensor = torch.tensor(labels)\n",
        "\n",
        "# Wrap everything into a TensorDataset and DataLoader\n",
        "dataset = TensorDataset(encoded_dict['input_ids'], encoded_dict['attention_mask'], labels_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32)  # adjust batch size as needed\n"
      ],
      "metadata": {
        "id": "V22-n4gT7eHQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "0nlwOz4b-qVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the directory\n",
        "model = BertForSequenceClassification.from_pretrained(save_directory)\n",
        "\n",
        "# Move the model to the correct device\n",
        "model.to(device)\n",
        "model.eval() # Set the model to evaluation mode\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "y_prob = []\n",
        "\n",
        "# Make a prediction\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels_batch = batch[2].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Softmax to get probabilities\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "        y_true.extend(labels_batch.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_prob.extend(probs[:, 1].cpu().numpy())  # prob of class \"Relevant\" (index 1)"
      ],
      "metadata": {
        "id": "wTx3F6LjzqSy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "kfpa_mD7-yoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Precision:\", precision_score(y_true, y_pred, zero_division=0))\n",
        "print(\"Recall:\", recall_score(y_true, y_pred, zero_division=0))\n",
        "print(\"F1:\", f1_score(y_true, y_pred, zero_division=0))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_true, y_prob))\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, zero_division=0))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "id": "htLmjczQ-2Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9be6ca2a-5198-4f9c-81f1-bc2e6303c8ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.978\n",
            "Precision: 0.9916492693110647\n",
            "Recall: 0.9854771784232366\n",
            "F1: 0.9885535900104059\n",
            "ROC AUC: 0.9560857538035962\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.78      0.72        18\n",
            "           1       0.99      0.99      0.99       482\n",
            "\n",
            "    accuracy                           0.98       500\n",
            "   macro avg       0.83      0.88      0.85       500\n",
            "weighted avg       0.98      0.98      0.98       500\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 14   4]\n",
            " [  7 475]]\n"
          ]
        }
      ]
    }
  ]
}